## Most of the data we will be relying in this course
## comes from packages alr4 and alr3
library(alr4)
library(alr3)
## Fuel consumption example
## Weisberg p15-18
?fuel2001
cars.data <- readRDS("carsdata.RDS")
getwd()
cars.data <- readRDS("carsdata.RDS")
head(cars.data)
cars.data1 <- cars.data[which(cars.data$cylinders %in% c(6,8)),]
cars.data1$cylinders <- as.factor(as.numeric(cars.data1$cylinders)-1)
head(cars.data1)
head( cars.data1$cylinders)
fit.cars1 <- lm(acceleration~weight+cylinders, data=cars.data1)
summary(fit.cars1)
predict(fit.cars1,data.frame(cylinders=as.factor(0),weight=c(3000)))
plot(acceleration~weight,data=cars.data1,col=c("red","blue")[cylinders],
main="Acceleration ~ Weight + Cylinders")
abline(a = fit.cars1$coefficients[1], b= fit.cars1$coefficients[2], col="red")
abline(a=fit.cars1$coefficients[1]+fit.cars1$coefficients[3],b=fit.cars1$coefficients[2], col="blue")
legend(4300,22.5,col=c("red","blue"),legend = c("cylinders = 6","cylinders = 8"),lty=c(1,1))
## categorical variable with 3 levels
fit.cars2 <- lm(acceleration~weight+cylinders,data=cars.data)
## categorical variable with 3 levels
fit.cars2 <- lm(acceleration~weight+cylinders,data=cars.data)
## categorical variable with 3 levels
fit.cars2 <- lm(acceleration~weight+cylinders,data=cars.data)
summary(fit.cars2)
## if cylinders was not encoded as factor
summary(lm(acceleration~weight+as.numeric(cylinders),data=cars.data))
## fitted values for weight =3000 and cylinders 6, 8
predict(fit.cars2,data.frame(cylinders=as.factor(6),weight=c(3000)))
16.118 +0.988 -4.965
predict(fit.cars2,data.frame(cylinders=as.factor(8),weight=c(3000)))
## plot the different fitted regression lines
plot(acceleration~weight,data=cars.data, col=c("green","red","blue")[cylinders],
main="Acceleration ~ Weight + Cylinders")
abline(a = fit.cars2$coefficients[1], b= fit.cars2$coefficients[2], col="green")
abline(a=fit.cars2$coefficients[1]+fit.cars2$coefficients[3],
b=fit.cars2$coefficients[2], col="red")
abline(a=fit.cars2$coefficients[1]+fit.cars2$coefficients[4],
b=fit.cars2$coefficients[2], col="blue")
legend(4000,25,col=c("green","red","blue"),legend = c("cylinders = 4","cylinders = 6","cylinders = 8"),lty=c(1,1))
## choose a different ref. level with function relevel()
cars.data2 <- within(cars.data, cylinders <- relevel(cylinders, ref = 2))
fit.cars3 <-  lm(acceleration~weight+cylinders,data=cars.data2)
## The coefficients and the p-values are different!
summary(fit.cars3)
## fit without the categorical predictor
fit.w <- lm(acceleration~weight,data=cars.data)
## test for the significance of the categorical predictor:
anova(fit.w,fit.cars2)
anova(fit.w,fit.cars3)
## doing the F-test (anova test) by hand
f <- (2406.7-1967)/1967*(387/2)
1-pf(f,2,387)
## including the interaction of weight and cylinders
fit.cars4 <- lm(acceleration~weight*cylinders,data=cars.data)
summary(fit.cars4)
## or
summary(lm(acceleration~weight+cylinders+weight:cylinders,data=cars.data))
## plotting the different regression lines
plot(acceleration~weight,data=cars.data, col=c("green","red","blue")[cylinders],
main="Acceleration ~ Weight * Cylinders")
abline(a = fit.cars4$coefficients[1], b= fit.cars4$coefficients[2], col="green")
abline(a=fit.cars4$coefficients[1]+fit.cars4$coefficients[3],
b=fit.cars4$coefficients[2]+fit.cars4$coefficients[5], col="red")
abline(a=fit.cars4$coefficients[1]+fit.cars4$coefficients[4],
b=fit.cars4$coefficients[2]+fit.cars4$coefficients[6], col="blue")
legend(4000,25,col=c("green","red","blue"),legend = c("cylinders = 4","cylinders = 6","cylinders = 8"),lty=c(1,1))
## fit with interaction and different ref. level:
fit.cars4.relev <- lm(acceleration~weight*cylinders,data=cars.data2)
## Now all p-values are significant at the .5 level!
summary(fit.cars4.relev)
anova(fit.cars3, fit.cars4)
## including some other predictors and interactions
fit.cars5 <- lm(acceleration~weight+cylinders+horsepower+mpg +
weight:cylinders + weight:horsepower + weight:mpg+
cylinders:horsepower + cylinders:mpg+
horsepower:mpg + weight:horsepower:mpg ,data=cars.data)
summary(fit.cars5)
## including polynomials of degree 2 and 3 for predictor weight
fit.cars6 <- lm(acceleration~weight+cylinders+horsepower+mpg +
weight:cylinders + weight:horsepower + weight:mpg+
cylinders:horsepower + cylinders:mpg+
horsepower:mpg + weight:horsepower:mpg +
I(weight^2) + I(weight^3),data=cars.data)
summary(fit.cars6)
## Consider using the function poly to add polynomials
?poly
dat1 <- as.matrix(data.frame(mpg=cars.data$mpg, horsepower=cars.data$horsepower,
weight=cars.data$weight))
fit.cars.star <-  lm(acceleration~poly(dat1,3),data=cars.data)
summary(fit.cars.star)
summary(fit.cars6)
?I
dat1
summary(fit.cars.star)
## Problems with correlated polynomials
dat2 <- as.matrix(data.frame(mpg=cars.data$mpg, mpg2 =cars.data$mpg^2, mpg3=cars.data$mpg^3,
horsepower=cars.data$horsepower, horsepower2=cars.data$horsepower^2,
horsepower3=cars.data$horsepower^2,
weight=cars.data$weight, weight2=cars.data$weight^2, weight3=cars.data$weight^2))
cor(dat2)
## Center the data
dat3 <- as.matrix(data.frame(mpg=scale(cars.data$mpg,scale=F), mpg2 =scale(cars.data$mpg,scale=F)^2,
mpg3=scale(cars.data$mpg,scale=F)^3,
horsepower=scale(cars.data$horsepower,scale=F),
horsepower2=scale(cars.data$horsepower,scale=F)^2,
horsepower3=scale(cars.data$horsepower,scale=F)^3,
weight=scale(cars.data$weight,scale=F),
weight2=scale(cars.data$weight,scale=F)^2,
weight3=scale(cars.data$weight,scale=F)^3))
cor(dat3)
## By contrast the correlations after using the poly function:
cor(poly(dat1,3))
library(faraway)
install.packages(far"faraway")
install.packages("faraway")
(faraway)
(faraway)
library(faraway)
data("savings")
data("savings")
head(savings)
?savings
fit1 <- lm(sr~. , data=savings)
summary(fit1)
## We will be talking about all 4 of the following plots,
## but for now we focus on the first plot
par(mfrow=c(2,2))
plot(fit1)
par(mfrow=c(1,1))
## Tukey-Anscombe plot
plot(fit1,which=1)
## or
plot(resid(fit1)~fitted(fit1), main="Residuals vs. Fitted")
abline(h=0)
## plotting residuals against predictors
par(mfrow=c(2,2))
plot(resid(fit1)~savings$pop15)
abline(h=0)
plot(resid(fit1)~savings$pop75)
abline(h=0)
plot(resid(fit1)~savings$dpi)
abline(h=0)
plot(resid(fit1)~savings$ddpi)
abline(h=0)
## From Faraway's book. Examples of:
par(mfrow=c(3,3))
## Constant Variance
for(i in 1:9) plot(1:50,rnorm(50))
## Strong non-constant variance
for(i in 1:9) plot(1:50,(1:50)*rnorm(50))
## Mild non-constant variance
for(i in 1:9) plot(1:50,sqrt((1:50))*rnorm(50))
## Non-linearity
for(i in 1:9) plot(1:50,cos((1:50)*pi/25)+rnorm(50))
## Residuals against index
par(mfrow=c(1,1))
plot(resid(fit1)~c(1:length(resid(fit1))), main="Residuals vs. Index",
xlab="Index", ylab="Residuals")
abline(h=0)
## standardized residuals vs. fitted
plot(rstandard(fit1)~fitted(fit1), main="Standardized residuals vs. fitted",
xlab = "Fitted values", ylab="Standardized residuals")
abline(h=0)
## studentized residuals vs. fitted
plot(rstudent(fit1)~fitted(fit1), main="Studentized residuals vs. fitted",
xlab = "Fitted values", ylab="Studentized residuals")
abline(h=0)
## Square root of the Standardized residuals vs fitted values
plot(fit1, which=3)
## examples for the normal QQ plot
set.seed(1)
par(mfrow=c(2,2))
qqnorm(rnorm(50), main="Standard Normal")
## Residuals against index
par(mfrow=c(1,1))
## standardized residuals vs. fitted
plot(rstandard(fit1)~fitted(fit1), main="Standardized residuals vs. fitted",
xlab = "Fitted values", ylab="Standardized residuals")
abline(h=0)
## studentized residuals vs. fitted
plot(rstudent(fit1)~fitted(fit1), main="Studentized residuals vs. fitted",
xlab = "Fitted values", ylab="Studentized residuals")
abline(h=0)
## Square root of the Standardized residuals vs fitted values
plot(fit1, which=3)
?cor
# Simulation: two independent Gaussians
set.seed(123)
x1 <- rnorm(100, mean=70, sd=15)
x2 <- rnorm(100, mean=70, sd=15)
# Add in a linear combination of X1 and X2
x3 <- (x1+x2)/2
pairs(cbind(x1,x2,x3))
cor(cbind(x1,x2,x3))
library(faraway)
?seatpos
fit.carseat <- lm(hipcenter~.,data=seatpos)
summary(fit.carseat)
library(corrplot)
install.packages("corrplot")
library(faraway)
?seatpos
fit.carseat <- lm(hipcenter~.,data=seatpos)
summary(fit.carseat)
library(corrplot)
par(mfrow=c(1,1))
corrplot(cor(seatpos[,-9]))
vif(fit.carseat)
?vif
corrplot(cor(seatpos[,-9]))
fit.carseat2 <- lm(hipcenter~Age + Weight +Ht, data=seatpos)
summary(fit.carseat2)
vif(fit.carseat2)
age    <- seatpos$Age
bmi    <- (seatpos$Weight*0.454)/(seatpos$Ht/100)^2
shoes  <- seatpos$HtShoes-seatpos$Ht
seated <- seatpos$Seated/seatpos$Ht
arm    <- seatpos$Arm/seatpos$Ht
thigh  <- seatpos$Thigh/seatpos$Ht
leg    <- seatpos$Leg/seatpos$Ht
seatpos.new <- data.frame(age=age,bmi=bmi,height=seatpos$Ht,
shoes=shoes,seated=seated,
arm=arm,thigh=thigh,leg=leg,hipcenter=seatpos$hipcenter)
fit.carseat3 <- lm(hipcenter~.,data=seatpos.new)
summary(fit.carseat3)
vif(fit.carseat3)
corrplot(cor(seatpos.new[,-9]))
?cor
?corrplot
dev.off()
library(faraway)
?star
data(star)
pdf("/Users/ema/uwdrive/stat 504/Slides/img/star1.pdf")
plot(light~temp,data=star)
dev.off()
pdf("/Users/ema/uwdrive/stat 504/Slides/img/star2.pdf")
hist(star$temp)
dev.off()
pdf("/Users/ema/uwdrive/stat 504/Slides/img/star3.pdf",height=4,width=8)
par(mfrow=c(1,3))
plot(light~temp,data=star)
hist(star$temp,main="Temperature")
boxplot(star$temp,main="Temperature")
dev.off()
pdf("/Users/ema/uwdrive/stat 504/Slides/img/star5.pdf")
par(mfrow=c(1,1))
plot(light~temp,data=star)
fit.star1 <- lm(light ~ temp, data=star)
abline(fit.star1, lwd=2,lty=1,col="red")
fit.star2 <- lm(light ~temp, data=star, subset=(temp>3.6))
abline(fit.star2,lwd=2,lty=2,col="blue")
legend(4.15,6.3,legend=c("all points","excluding outliers"),lty=c(1,2),
col=c("red","blue"),lwd=c(2,2))
dev.off()
library(alr4)
